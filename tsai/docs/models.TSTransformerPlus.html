---

title: TSTransformerPlus


keywords: fastai
sidebar: home_sidebar

summary: "This is a PyTorch implementation created by Ignacio Oguiza (timeseriesAI@gmail.com)."
description: "This is a PyTorch implementation created by Ignacio Oguiza (timeseriesAI@gmail.com)."
nb_path: "nbs/124_models.TSTransformerPlus.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/124_models.TSTransformerPlus.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TSTransformerPlus" class="doc_header"><code>class</code> <code>TSTransformerPlus</code><a href="https://github.com/timeseriesAI/tsai/tree/main/tsai/models/TSTransformerPlus.py#L83" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TSTransformerPlus</code>(<strong><code>c_in</code></strong>:<code>int</code>, <strong><code>c_out</code></strong>:<code>int</code>, <strong><code>seq_len</code></strong>:<code>int</code>, <strong><code>n_layers</code></strong>:<code>int</code>=<em><code>6</code></em>, <strong><code>d_model</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>n_heads</code></strong>:<code>int</code>=<em><code>16</code></em>, <strong><code>d_head</code></strong>:<code>Optional</code>[<code>int</code>]=<em><code>None</code></em>, <strong><code>act</code></strong>:<code>str</code>=<em><code>'reglu'</code></em>, <strong><code>d_ff</code></strong>:<code>int</code>=<em><code>256</code></em>, <strong><code>pos_dropout</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>attn_drop_rate</code></strong>:<code>float</code>=<em><code>0</code></em>, <strong><code>mlp_drop_rate</code></strong>:<code>float</code>=<em><code>0</code></em>, <strong><code>drop_path_rate</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>pre_norm</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>use_cls_token</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>pct_random_steps</code></strong>:<code>float</code>=<em><code>1.0</code></em>, <strong><code>fc_dropout</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>bn</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>y_range</code></strong>:<code>Optional</code>[<code>tuple</code>]=<em><code>None</code></em>, <strong><code>custom_subsampling</code></strong>:<code>Optional</code>[<code>Callable</code>]=<em><code>None</code></em>, <strong><code>custom_head</code></strong>:<code>Optional</code>[<code>Callable</code>]=<em><code>None</code></em>, <strong><code>verbose</code></strong>:<code>bool</code>=<em><code>True</code></em>) :: <a href="/models.TabFusionTransformer.html#Sequential"><code>Sequential</code></a></p>
</blockquote>
<p>Time series transformer model based on ViT (Vision Transformer):</p>
<p>Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... &amp; Houlsby, N. (2020).
An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.</p>
<p>Args:
    c_in: the number of features (aka variables, dimensions, channels) in the time series dataset.
    c_out: the number of target classes.
    seq_len: number of time steps in the time series.
    n_layers: number of layers (or blocks) in the encoder. Default: 3 (range(1-4))
    d_model: total dimension of the model (number of features created by the model). Default: 128 (range(64-512))
    n_heads:  parallel attention heads. Default:16 (range(8-16)).
    d_head: size of the learned linear projection of queries, keys and values in the MHA. Usual values: 16-512. Default: None -&gt; (d_model/n_heads) = 32.
    act: the activation function of intermediate layer, relu, gelu, geglu, reglu.
    d_ff: the dimension of the feedforward network model. Default: 512 (range(256-512))
    pos_dropout: dropout applied to to the embedded sequence steps after position embeddings have been added.
    attn_drop_rate (float): dropout rate applied to the attention layer
    mlp_drop_rate (float): dropout rate applied to the mlp layer
    drop_path_rate: dropout applied to the output of MultheadAttention and PositionwiseFeedForward layers.
    pre_norm: if True normalization will be applied as the first step in the sublayers. Defaults to False.
    use_cls_token: if True, the output will come from the transformed class token. Otherwise a pooling layer will be applied.
    pct_random_steps: percent of steps that will be chosen during training (with replacement)
    fc_dropout: dropout applied to the final fully connected layer.
    bn: indicates if batchnorm will be applied to the head.
    y_range: range of possible y values (used in regression tasks).
    custom_subsampling: an optional callable (nn.Conv1d with dilation &gt; 1 or stride &gt; 1for example) that will be used to reduce the sequence length.
    custom_head: custom head that will be applied to the network. It must contain all kwargs (pass a partial function)</p>
<p>Input shape:
    x: bs (batch size) x nvars (aka features, variables, dimensions, channels) x seq_len (aka time steps)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">nvars</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">c_out</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">xb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">nvars</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TSTransformerPlus</span><span class="p">(</span><span class="n">nvars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">))</span>
<span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TSTransformerPlus(
  (backbone): _TSTransformerBackbone(
    (to_embedding): Sequential(
      (0): Transpose(1, 2)
      (1): Linear(in_features=4, out_features=128, bias=True)
    )
    (pos_dropout): Dropout(p=0.0, inplace=False)
    (encoder): _TransformerEncoder(
      (layers): ModuleList(
        (0): ModuleList(
          (0): MultiheadAttention(
            (W_Q): Linear(in_features=128, out_features=128, bias=False)
            (W_K): Linear(in_features=128, out_features=128, bias=False)
            (W_V): Linear(in_features=128, out_features=128, bias=False)
            (sdp_attn): ScaledDotProductAttention()
            (to_out): Sequential(
              (0): Linear(in_features=128, out_features=128, bias=True)
              (1): Dropout(p=0, inplace=False)
            )
          )
          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (2): PositionwiseFeedForward(
            (0): Linear(in_features=128, out_features=256, bias=True)
            (1): ReGLU()
            (2): Dropout(p=0, inplace=False)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): Dropout(p=0, inplace=False)
          )
          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (4): Identity()
        )
        (1): ModuleList(
          (0): MultiheadAttention(
            (W_Q): Linear(in_features=128, out_features=128, bias=False)
            (W_K): Linear(in_features=128, out_features=128, bias=False)
            (W_V): Linear(in_features=128, out_features=128, bias=False)
            (sdp_attn): ScaledDotProductAttention()
            (to_out): Sequential(
              (0): Linear(in_features=128, out_features=128, bias=True)
              (1): Dropout(p=0, inplace=False)
            )
          )
          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (2): PositionwiseFeedForward(
            (0): Linear(in_features=128, out_features=256, bias=True)
            (1): ReGLU()
            (2): Dropout(p=0, inplace=False)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): Dropout(p=0, inplace=False)
          )
          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (4): Identity()
        )
        (2): ModuleList(
          (0): MultiheadAttention(
            (W_Q): Linear(in_features=128, out_features=128, bias=False)
            (W_K): Linear(in_features=128, out_features=128, bias=False)
            (W_V): Linear(in_features=128, out_features=128, bias=False)
            (sdp_attn): ScaledDotProductAttention()
            (to_out): Sequential(
              (0): Linear(in_features=128, out_features=128, bias=True)
              (1): Dropout(p=0, inplace=False)
            )
          )
          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (2): PositionwiseFeedForward(
            (0): Linear(in_features=128, out_features=256, bias=True)
            (1): ReGLU()
            (2): Dropout(p=0, inplace=False)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): Dropout(p=0, inplace=False)
          )
          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (4): Identity()
        )
        (3): ModuleList(
          (0): MultiheadAttention(
            (W_Q): Linear(in_features=128, out_features=128, bias=False)
            (W_K): Linear(in_features=128, out_features=128, bias=False)
            (W_V): Linear(in_features=128, out_features=128, bias=False)
            (sdp_attn): ScaledDotProductAttention()
            (to_out): Sequential(
              (0): Linear(in_features=128, out_features=128, bias=True)
              (1): Dropout(p=0, inplace=False)
            )
          )
          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (2): PositionwiseFeedForward(
            (0): Linear(in_features=128, out_features=256, bias=True)
            (1): ReGLU()
            (2): Dropout(p=0, inplace=False)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): Dropout(p=0, inplace=False)
          )
          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (4): Identity()
        )
        (4): ModuleList(
          (0): MultiheadAttention(
            (W_Q): Linear(in_features=128, out_features=128, bias=False)
            (W_K): Linear(in_features=128, out_features=128, bias=False)
            (W_V): Linear(in_features=128, out_features=128, bias=False)
            (sdp_attn): ScaledDotProductAttention()
            (to_out): Sequential(
              (0): Linear(in_features=128, out_features=128, bias=True)
              (1): Dropout(p=0, inplace=False)
            )
          )
          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (2): PositionwiseFeedForward(
            (0): Linear(in_features=128, out_features=256, bias=True)
            (1): ReGLU()
            (2): Dropout(p=0, inplace=False)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): Dropout(p=0, inplace=False)
          )
          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (4): Identity()
        )
        (5): ModuleList(
          (0): MultiheadAttention(
            (W_Q): Linear(in_features=128, out_features=128, bias=False)
            (W_K): Linear(in_features=128, out_features=128, bias=False)
            (W_V): Linear(in_features=128, out_features=128, bias=False)
            (sdp_attn): ScaledDotProductAttention()
            (to_out): Sequential(
              (0): Linear(in_features=128, out_features=128, bias=True)
              (1): Dropout(p=0, inplace=False)
            )
          )
          (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (2): PositionwiseFeedForward(
            (0): Linear(in_features=128, out_features=256, bias=True)
            (1): ReGLU()
            (2): Dropout(p=0, inplace=False)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): Dropout(p=0, inplace=False)
          )
          (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (4): Identity()
        )
      )
    )
  )
  (head): Sequential(
    (0): TokenLayer()
    (1): LinBnDrop(
      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): Linear(in_features=128, out_features=2, bias=False)
    )
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Subsampling">Subsampling<a class="anchor-link" href="#Subsampling"> </a></h3><p>It's a known fact that transformers cannot be directly applied to long sequences. To avoid this, we have included a way to subsample the sequence to generate a more manageable input.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tsai.data.validation</span> <span class="kn">import</span> <span class="n">get_splits</span>
<span class="kn">from</span> <span class="nn">tsai.data.core</span> <span class="kn">import</span> <span class="n">get_ts_dls</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5000</span><span class="p">))</span> 
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">get_splits</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">get_ts_dls</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">)</span>
<span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">xb</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TSTensor(samples:8, vars:3, len:5000)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you try to use TSTransformerPlus, it's likely you'll get an 'out-of-memory' error.</p>
<p>To avoid this you can subsample the sequence reducing the input's length. This can be done in multiple ways. Here are a few examples:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">custom_subsampling</span> <span class="o">=</span> <span class="n">Conv1d</span><span class="p">(</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ks</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">())</span>
<span class="n">custom_subsampling</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([8, 3, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">custom_subsampling</span> <span class="o">=</span> <span class="n">Conv1d</span><span class="p">(</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ks</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">())</span>
<span class="n">custom_subsampling</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([8, 2, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">custom_subsampling</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Pad1d</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">())</span>
<span class="n">custom_subsampling</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([8, 3, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">custom_subsampling</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Pad1d</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">default_device</span><span class="p">())</span>
<span class="n">custom_subsampling</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([8, 3, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once you decide what type of transform you want to apply, you just need to pass the layer as the custom_subsampling attribute:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">nvars</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">c_out</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">xb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">nvars</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
<span class="n">custom_subsampling</span> <span class="o">=</span> <span class="n">Conv1d</span><span class="p">(</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ks</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TSTransformerPlus</span><span class="p">(</span><span class="n">nvars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">custom_subsampling</span><span class="o">=</span><span class="n">custom_subsampling</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>custom_subsampling: (?, 4, 1000) --&gt; (?, 4, 334)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

